# This file generated by Quarto; do not edit by hand.
# shiny_mode: core

from __future__ import annotations

from pathlib import Path
from shiny import App, Inputs, Outputs, Session, ui

import pandas as pd
import plotly.express as px
import pickle
from sklearn.manifold import TSNE
from sklearn.decomposition import SparsePCA
from sklearn.preprocessing import StandardScaler
import numpy as np
from shiny.express import input, render, ui
from shinywidgets import render_plotly
import numpyro
from tensorly.decomposition import tucker
numpyro.set_platform("cpu")

# ========================================================================

from data.data_utils import create_fda_data
data = pd.read_csv("data/player_data.csv").query(" age <= 38 ")
names = data.groupby("id")["name"].first().values
names_df = pd.DataFrame(names, columns = ["Name"])
names_df["Player"] = range(len(names))
metric_output = ["binomial", "exponential"] + (["gaussian"] * 2) + (["poisson"] * 9) + (["binomial"] * 3)
metrics = ["retirement", "minutes", "obpm","dbpm","blk","stl","ast","dreb","oreb","tov","fta","fg2a","fg3a","ftm","fg2m","fg3m"]
metric_df = pd.DataFrame(metrics, columns=["Statistic"])
metric_df["Metric"] = range(len(metrics))
age_df = pd.DataFrame(range(18,39), columns = ["Age"])
age_df["Time"] = age_df["Age"] - 18
exposure_list = (["simple_exposure"] * 2) + (["minutes"] * 11) + ["fta","fg2a","fg3a"]
data["retirement"] = 1
data["log_min"] = np.log(data["minutes"])
data["simple_exposure"] = 1 
_ , outputs, _ = create_fda_data(data, basis_dims=3, metric_output=metric_output, 
                                     metrics = metrics
, exposure_list =  exposure_list)
observations = np.stack([output["output_data"] for output in outputs], axis = 1)
exposures = np.stack([output["exposure_data"] for output in outputs], axis = 0)

agg_dict = {"obpm":"mean", "dbpm":"mean", "bpm":"mean", 
            "position_group": "max",
        "minutes":"sum", "dreb": "sum", "fta":"sum", "ftm":"sum", "oreb":"sum",
        "ast":"sum", "tov":"sum", "fg2m":"sum", "fg3m":"sum", "fg3a":"sum", "fg2a":"sum", "blk":"sum", "stl":"sum"}
data["total_minutes"] = data["median_minutes_per_game"] * data["games"] 
agged_data = data.groupby("id").agg(agg_dict).reset_index()
agged_data["ft_pct"] = agged_data["ftm"] / agged_data["fta"]
agged_data["fg2_pct"] = agged_data["fg2m"] / agged_data["fg2a"]
agged_data["fg3_pct"] = agged_data["fg3m"] / agged_data["fg3a"]
agged_data["dreb_rate"] = 36.0 * agged_data["dreb"] / agged_data["minutes"]
agged_data["oreb_rate"] = 36.0 * agged_data["oreb"] / agged_data["minutes"]
agged_data["ast_rate"] = 36.0 * agged_data["ast"] / agged_data["minutes"]
agged_data["tov_rate"] = 36.0 * agged_data["tov"] / agged_data["minutes"]
agged_data["blk_rate"] = 36.0 * agged_data["blk"] / agged_data["minutes"]
agged_data["stl_rate"] = 36.0 * agged_data["stl"] / agged_data["minutes"]
agged_data["ft_rate"] = 36.0 * agged_data["fta"] / agged_data["minutes"]
agged_data["fg2_rate"] = 36.0 * agged_data["fg2a"] / agged_data["minutes"]
agged_data["fg3_rate"] = 36.0 * agged_data["fg3a"] / agged_data["minutes"]
agged_data.fillna(0, inplace=True)

# ========================================================================

N, K, T = observations.shape

edges = []
nodes = []
vals = []
missing = []
for player_index in range(N):
    for metric_index in range(K):
        for time_index in range(T):
            cur_node = (player_index, metric_index, time_index)
            nodes.append(cur_node)
            missing.append(np.isfinite(exposures[metric_index, player_index, time_index]))
            vals.append(observations[player_index, metric_index, time_index])

            if player_index != N - 1:
                edges.append((cur_node, (player_index + 1, metric_index ,time_index)))

            if player_index != 0:
                edges.append((cur_node, (player_index - 1, metric_index, time_index )))
            
            if metric_index != K - 1:
                edges.append((cur_node, (player_index, metric_index + 1, time_index)))

            if metric_index != 0:
                edges.append((cur_node, (player_index, metric_index - 1, time_index)))

            if time_index != T - 1:
                edges.append((cur_node, (player_index, metric_index, time_index + 1)))

            if time_index != 0:
                edges.append((cur_node, (player_index, metric_index, time_index - 1)))

nodes_df = pd.DataFrame(np.array([list(x) for x in zip(*nodes)]).T, columns=["Player", "Metric", "Time"])
nodes_df["Value"] = vals
nodes_df["Missing"] = missing

final_data_plot_df = pd.merge(nodes_df, names_df).merge(metric_df).merge(age_df)

# ========================================================================




def server(input: Inputs, output: Outputs, session: Session) -> None:
    with open("model_output/exponential_cp_test.pkl", "rb") as f:
        results = pickle.load(f)
    f.close()

    X = results["U_auto_loc"]

    U, _, _ = np.linalg.svd(X, full_matrices=False)
    L       = np.linalg.cholesky(np.cov(U.T) + 1e-6 * np.eye(7)).T
    aligned_X  = np.linalg.solve(L, U.T).T
    aligned_X /= np.std(X, axis=0)

    X_tsne = TSNE(n_components=3).fit_transform(aligned_X)


    scatter_df = pd.concat([pd.DataFrame(X_tsne, columns=[f"dim{i+1}" for i in range(3)]), agged_data], axis = 1)
    scatter_df["player_name"] = names


    # ========================================================================

    import jax.numpy as jnp
    with open("model_output/fixed_nba_tvrflvm_test.pkl", "rb") as f:
        results_tvrflvm = pickle.load(f)
    f.close()

    W = results_tvrflvm["W"]
    # mu_dims = []
    # for i in range(aligned_X.shape[0]):
    #     wTx = jnp.einsum("r,ijmr -> ijm", aligned_X[i], W)
    #     phi = jnp.concatenate([jnp.cos(wTx), jnp.sin(wTx)], -1) * (1/ jnp.sqrt(100))
    #     mu = jnp.einsum("ijk,ijmkt -> ijmt", phi, results_tvrflvm["beta"]).mean((0,1)).T
    #     mu  = StandardScaler().fit_transform(mu)
    #     mu_dims.append(mu)
    # mu = jnp.stack(mu_dims)
    # del mu_dims
    # core, factors = tucker(mu, rank = [aligned_X.shape[0], 3, len(metrics)])

    with open("model_output/tensor_decomposition.pkl", "rb") as f:
        results_tensor = pickle.load(f)
    f.close()
    core, factors, mu = results_tensor["core"], results_tensor["factors"], results_tensor["mu"]
    full_core = np.einsum("nkl,lj -> nkj", np.einsum("nc,ckl -> nkl", factors[0], core), factors[2])

    # ========================================================================

    from visualization.visualization import plot_career_trajectory_observations
    ui.input_select(id="player_traj", label = "Select a player", choices = {index : name for index, name in enumerate(names)})
    @render_plotly
    def plot_metric_arc():
        return plot_career_trajectory_observations(int(input.player_traj()), metrics, metric_output, observations, exposures )

    # ========================================================================

    from visualization.visualization import plot_data_tensor
    @render_plotly
    def plot_data():
        return plot_data_tensor(final_data_plot_df)

    # ========================================================================

    from visualization.visualization import plot_scatter
    ui.input_select(id="player", label = "Select a player", choices = {index : name for index, name in enumerate(names)})

    @render_plotly
    def plot_latent_space():
        return plot_scatter(scatter_df,  "Latent Embedding", int(input.player()) )

    # ========================================================================

    with ui.layout_column_wrap():
        ui.input_select(id="player_functional", label = "Select a player", choices = {index : name for index, name in enumerate(names)})
    with ui.layout_column_wrap():
        @render_plotly
        def plot_functional_bases():
            player_index = int(input.player_functional())
            # mu_player = core[player_index].T 
            # standardized_mu = StandardScaler().fit_transform(mu_player)
            # functional_pca = SparsePCA(n_components=3, alpha=1)
            # functional_pca.fit(standardized_mu)
            explained_var = full_core[player_index].T.var(0)
            funct_bases_df = pd.DataFrame(factors[1], columns = [f"Basis {i}: {explained_var[i-1]/16:.{3}}% EV" for i in range(1,4)])
            funct_bases_df["Age"] = range(18,39)
            funct_bases_melted = funct_bases_df.melt(id_vars="Age", var_name="Variable", value_name="Value")
            fig = px.line(funct_bases_melted, x = "Age", y = "Value", color="Variable")
            return fig
        @render_plotly
        def plot_metric_weights():
            player_index = int(input.player_functional())
            # mu_player = mu[player_index].T 
            # standardized_mu = StandardScaler().fit_transform(mu_player)
            # functional_pca = SparsePCA(n_components=3, alpha=1)
            # functional_pca.fit(standardized_mu)
            weights = full_core[player_index] - full_core.mean(0)
            weights_df = pd.DataFrame(weights, columns = metrics)
            weights_df["Basis"] = range(1,4)
            weights_df_melted = weights_df.melt(id_vars="Basis", var_name="Variable", value_name="Value")
            fig = px.bar(weights_df_melted, facet_row="Basis",x="Variable", y = "Value")
            return fig


    # ========================================================================

    from visualization.visualization import plot_posterior_predictive_career_trajectory
    import jax.numpy as jnp
    ui.input_select(id="player_posterior", label = "Select a player", choices = {index : name for index, name in enumerate(names)})


    @render_plotly
    def plot_posterior_predictive():
        player_index = int(input.player_posterior())
        wTx = jnp.einsum("r,ijmr -> ijm", aligned_X[player_index, :], W)
        phi = jnp.concatenate([jnp.cos(wTx), jnp.sin(wTx)], -1) * (1/ jnp.sqrt(100))
        mu = jnp.einsum("ijk,ijmkt -> ijmt", phi, results_tvrflvm["beta"])
    
        return plot_posterior_predictive_career_trajectory(
                                                                player_index=player_index,
                                                                metrics=metrics, 
                                                                metric_outputs=metric_output,
                                                                posterior_mean_samples=mu,
                                                                observations=jnp.array(observations), 
                                                                exposures = jnp.array(exposures),
                                                                posterior_variance_samples=jnp.stack([results_tvrflvm["sigma_obpm"], results_tvrflvm["sigma_dbpm"]], axis = 0))

    # ========================================================================



    return None


_static_assets = ["advancement_files","images/noun-deep-learning-1705425.png","images/noun-scatter-graph-4768711.png","images/pgm.svg","images/pmg_corr.svg","images/tuckerdecomp.png"]
_static_assets = {"/" + sa: Path(__file__).parent / sa for sa in _static_assets}

app = App(
    Path(__file__).parent / "advancement.html",
    server,
    static_assets=_static_assets,
)
